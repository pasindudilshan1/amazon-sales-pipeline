version: '3.8'
services:
    zookeeper:
        image: confluentinc/cp-zookeeper:7.5.0
        container_name: zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        ports:
            - "2181:2181"

    kafka:
        image: confluentinc/cp-kafka:7.5.0
        container_name: kafka
        depends_on:
            - zookeeper
        ports:
            - "9092:9092"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    
    postgres:
        image: postgres:13
        container_name: postgres
        environment:
            POSTGRES_USER: airflow
            POSTGRES_PASSWORD: airflow
            POSTGRES_DB: airflow
        ports:
            - "5432:5432"
        volumes:
            - postgres-db-volume:/var/lib/postgresql/data
    
    airflow-webserver:
        image: apache/airflow:2.7.3
        container_name: airflow-webserver
        depends_on:
            - postgres
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
            AIRFLOW__CORE__FERNET_KEY: ''
            AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
            AIRFLOW__CORE__LOAD_EXAMPLE: 'false'
            AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
        volumes:
            - ./airflow/dags:/opt/airflow/dags
            - ./data:/opt/airflow/data
            - ./spark:/opt/airflow/spark
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
            interval: 1m30s
            timeout: 30s
            retries: 5
            start_period: 30s

    airflow-scheduler:
        image: apache/airflow:2.7.3
        container_name: airflow-scheduler
        depends_on:
            - postgres
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
            AIRFLOW__CORE__FERNET_KEY: ''
            AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
            AIRFLOW__CORE__LOAD_EXAMPLE: 'false'
        volumes:
            - ./airflow/dags:/opt/airflow/dags
            - ./data:/opt/airflow/data
            - ./spark:/opt/airflow/spark
        
        command: scheduler

    airflow-init:
        image: apache/airflow:2.7.3
        container_name: airflow-init
        depends_on:
            - postgres
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
            AIRFLOW__CORE__FERNET_KEY: ''
        volumes:
            - ./airflow/dags:/opt/airflow/dags
        entrypoint: /bin/bash
        command:
            - -c
            - |
              airflow db init
              airflow users create \
                --username admin \
                --firstname Admin \
                --lastname User \
                --role Admin \
                --email admin@example.com \
                --password admin

volumes:
    postgres-db-volume:



